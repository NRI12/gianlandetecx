{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12800,) (3200,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 211\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    210\u001b[0m tm\u001b[38;5;241m.\u001b[39mstart()\u001b[38;5;66;03m# for calculating FPS\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m bboxes, lmarks, scores \u001b[38;5;241m=\u001b[39m \u001b[43mmynet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# face detection\u001b[39;00m\n\u001b[1;32m    212\u001b[0m tm\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# process if at least one face detected\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 79\u001b[0m, in \u001b[0;36mSCRFD.detect\u001b[0;34m(self, srcimg)\u001b[0m\n\u001b[1;32m     76\u001b[0m     anchor_centers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([anchor_centers] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_anchors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     78\u001b[0m pos_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(scores \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfThreshold)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance2bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m pos_scores \u001b[38;5;241m=\u001b[39m scores[pos_inds]\n\u001b[1;32m     81\u001b[0m pos_bboxes \u001b[38;5;241m=\u001b[39m bboxes[pos_inds]\n",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m, in \u001b[0;36mSCRFD.distance2bbox\u001b[0;34m(self, points, distance, max_shape)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance2bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, points, distance, max_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 36\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m points[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m distance[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m points[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m distance[:, \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12800,) (3200,) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class SCRFD():\n",
    "    def __init__(self, onnxmodel, confThreshold=0.5, nmsThreshold=0.5):\n",
    "        self.inpWidth = 640\n",
    "        self.inpHeight = 640\n",
    "        self.confThreshold = confThreshold\n",
    "        self.nmsThreshold = nmsThreshold\n",
    "        self.net = cv2.dnn.readNet(onnxmodel)\n",
    "        #self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        #self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        self.keep_ratio = True\n",
    "        self.fmc = 3\n",
    "        self._feat_stride_fpn = [8, 16, 32]\n",
    "        self._num_anchors = 2\n",
    "    def resize_image(self, srcimg):\n",
    "        padh, padw, newh, neww = 0, 0, self.inpHeight, self.inpWidth\n",
    "        if self.keep_ratio and srcimg.shape[0] != srcimg.shape[1]:\n",
    "            hw_scale = srcimg.shape[0] / srcimg.shape[1]\n",
    "            if hw_scale > 1:\n",
    "                newh, neww = self.inpHeight, int(self.inpWidth / hw_scale)\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                padw = int((self.inpWidth - neww) * 0.5)\n",
    "                img = cv2.copyMakeBorder(img, 0, 0, padw, self.inpWidth - neww - padw, cv2.BORDER_CONSTANT,\n",
    "                                         value=0)  # add border\n",
    "            else:\n",
    "                newh, neww = int(self.inpHeight * hw_scale) + 1, self.inpWidth\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                padh = int((self.inpHeight - newh) * 0.5)\n",
    "                img = cv2.copyMakeBorder(img, padh, self.inpHeight - newh - padh, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
    "        else:\n",
    "            img = cv2.resize(srcimg, (self.inpWidth, self.inpHeight), interpolation=cv2.INTER_AREA)\n",
    "        return img, newh, neww, padh, padw\n",
    "    def distance2bbox(self, points, distance, max_shape=None):\n",
    "        x1 = points[:, 0] - distance[:, 0]\n",
    "        y1 = points[:, 1] - distance[:, 1]\n",
    "        x2 = points[:, 0] + distance[:, 2]\n",
    "        y2 = points[:, 1] + distance[:, 3]\n",
    "        if max_shape is not None:\n",
    "            x1 = x1.clamp(min=0, max=max_shape[1])\n",
    "            y1 = y1.clamp(min=0, max=max_shape[0])\n",
    "            x2 = x2.clamp(min=0, max=max_shape[1])\n",
    "            y2 = y2.clamp(min=0, max=max_shape[0])\n",
    "        return np.stack([x1, y1, x2, y2], axis=-1)\n",
    "    def distance2kps(self, points, distance, max_shape=None):\n",
    "        preds = []\n",
    "        for i in range(0, distance.shape[1], 2):\n",
    "            px = points[:, i % 2] + distance[:, i]\n",
    "            py = points[:, i % 2 + 1] + distance[:, i + 1]\n",
    "            if max_shape is not None:\n",
    "                px = px.clamp(min=0, max=max_shape[1])\n",
    "                py = py.clamp(min=0, max=max_shape[0])\n",
    "            preds.append(px)\n",
    "            preds.append(py)\n",
    "        return np.stack(preds, axis=-1)\n",
    "    def detect(self, srcimg):\n",
    "        img, newh, neww, padh, padw = self.resize_image(srcimg)\n",
    "        blob = cv2.dnn.blobFromImage(img, 1.0 / 128, (self.inpWidth, self.inpHeight), (127.5, 127.5, 127.5), swapRB=True)\n",
    "        # Sets the input to the network\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers\n",
    "        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "        # inference output\n",
    "        scores_list, bboxes_list, kpss_list = [], [], []\n",
    "        for idx, stride in enumerate(self._feat_stride_fpn):\n",
    "            scores = outs[idx * self.fmc][0]\n",
    "            bbox_preds = outs[idx * self.fmc + 1][0] * stride\n",
    "            kps_preds = outs[idx * self.fmc + 2][0] * stride\n",
    "            height = blob.shape[2] // stride\n",
    "            width = blob.shape[3] // stride\n",
    "            anchor_centers = np.stack(np.mgrid[:height, :width][::-1], axis=-1).astype(np.float32)\n",
    "            anchor_centers = (anchor_centers * stride).reshape((-1, 2))\n",
    "            if self._num_anchors > 1:\n",
    "                anchor_centers = np.stack([anchor_centers] * self._num_anchors, axis=1).reshape((-1, 2))\n",
    "\n",
    "            pos_inds = np.where(scores >= self.confThreshold)[0]\n",
    "            bboxes = self.distance2bbox(anchor_centers, bbox_preds)\n",
    "            pos_scores = scores[pos_inds]\n",
    "            pos_bboxes = bboxes[pos_inds]\n",
    "            scores_list.append(pos_scores)\n",
    "            bboxes_list.append(pos_bboxes)\n",
    "\n",
    "            kpss = self.distance2kps(anchor_centers, kps_preds)\n",
    "            kpss = kpss.reshape((kpss.shape[0], -1, 2))\n",
    "            pos_kpss = kpss[pos_inds]\n",
    "            kpss_list.append(pos_kpss)\n",
    "\n",
    "        scores = np.vstack(scores_list).ravel()\n",
    "        # bboxes = np.vstack(bboxes_list) / det_scale\n",
    "        # kpss = np.vstack(kpss_list) / det_scale\n",
    "        bboxes = np.vstack(bboxes_list)\n",
    "        kpss = np.vstack(kpss_list)\n",
    "        bboxes[:, 2:4] = bboxes[:, 2:4] - bboxes[:, 0:2]\n",
    "        ratioh, ratiow = srcimg.shape[0] / newh, srcimg.shape[1] / neww\n",
    "        bboxes[:, 0] = (bboxes[:, 0] - padw) * ratiow\n",
    "        bboxes[:, 1] = (bboxes[:, 1] - padh) * ratioh\n",
    "        bboxes[:, 2] = bboxes[:, 2] * ratiow\n",
    "        bboxes[:, 3] = bboxes[:, 3] * ratioh\n",
    "        kpss[:, :, 0] = (kpss[:, :, 0] - padw) * ratiow\n",
    "        kpss[:, :, 1] = (kpss[:, :, 1] - padh) * ratioh\n",
    "        indices = cv2.dnn.NMSBoxes(bboxes.tolist(), scores.tolist(), self.confThreshold, self.nmsThreshold)\n",
    "        \n",
    "        '''\n",
    "        for i in indices:\n",
    "            #i = i[0]\n",
    "            xmin, ymin, xamx, ymax = int(bboxes[i, 0]), int(bboxes[i, 1]), int(bboxes[i, 0] + bboxes[i, 2]), int(bboxes[i, 1] + bboxes[i, 3])\n",
    "            cv2.rectangle(srcimg, (xmin, ymin), (xamx, ymax), (0, 0, 255), thickness=2)\n",
    "            for j in range(5):\n",
    "                cv2.circle(srcimg, (int(kpss[i, j, 0]), int(kpss[i, j, 1])), 1, (0,255,0), thickness=-1)\n",
    "            cv2.putText(srcimg, str(round(scores[i], 3)), (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=1)\n",
    "        '''\n",
    "        return bboxes[indices], kpss[indices], scores[indices]#indices#srcimg\n",
    "\n",
    "def visualize(image, boxes, lmarks, scores, fps=0):\n",
    "    for i in range(len(boxes)):\n",
    "        xmin, ymin, xmax, ymax = int(boxes[i, 0]), int(boxes[i, 1]), int(boxes[i, 0] + boxes[i, 2]), int(boxes[i, 1] + boxes[i, 3])\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), thickness=2)\n",
    "        for j in range(5):\n",
    "            cv2.circle(image, (int(lmarks[i, j, 0]), int(lmarks[i, j, 1])), 1, (0,255,0), thickness=-1)\n",
    "        cv2.putText(frame, str(round(scores[i], 3)), (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=1)\n",
    "        cv2.putText(image, f\"FPS={int(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=1)\n",
    "    return image        \n",
    "\n",
    "def are_coordinates_in_frame(frame, box, pts):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : uint8\n",
    "        RGB image (numpy array).\n",
    "    bbs : float64\n",
    "        coordinates of bounding box.\n",
    "    points : flaot32\n",
    "        coordinates of landmarks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    if np.any(box <= 0) or np.any(box >= height) or np.any(box >= width):\n",
    "        return False\n",
    "    if np.any(pts <= 0) or np.any(pts >= height) or np.any(pts >= width):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def find_pose(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : float32, Size = (5,2)\n",
    "        coordinates of landmarks for the selected faces.\n",
    "    Returns\n",
    "    -------\n",
    "    float32, float32, float32\n",
    "    \"\"\"\n",
    "    LMx = points[:,0]#points[0:5]# horizontal coordinates of landmarks\n",
    "    LMy = points[:,1]#[5:10]# vertical coordinates of landmarks\n",
    "    \n",
    "    dPx_eyes = max((LMx[1] - LMx[0]), 1)\n",
    "    dPy_eyes = (LMy[1] - LMy[0])\n",
    "    angle = np.arctan(dPy_eyes / dPx_eyes) # angle for rotation based on slope\n",
    "    \n",
    "    alpha = np.cos(angle)\n",
    "    beta = np.sin(angle)\n",
    "    \n",
    "    # rotated landmarks\n",
    "    LMxr = (alpha * LMx + beta * LMy + (1 - alpha) * LMx[2] / 2 - beta * LMy[2] / 2) \n",
    "    LMyr = (-beta * LMx + alpha * LMy + beta * LMx[2] / 2 + (1 - alpha) * LMy[2] / 2)\n",
    "    \n",
    "    # average distance between eyes and mouth\n",
    "    dXtot = (LMxr[1] - LMxr[0] + LMxr[4] - LMxr[3]) / 2\n",
    "    dYtot = (LMyr[3] - LMyr[0] + LMyr[4] - LMyr[1]) / 2\n",
    "    \n",
    "    # average distance between nose and eyes\n",
    "    dXnose = (LMxr[1] - LMxr[2] + LMxr[4] - LMxr[2]) / 2\n",
    "    dYnose = (LMyr[3] - LMyr[2] + LMyr[4] - LMyr[2]) / 2\n",
    "    \n",
    "    # relative rotation 0 degree is frontal 90 degree is profile\n",
    "    Xfrontal = (-90+90 / 0.5 * dXnose / dXtot) if dXtot != 0 else 0\n",
    "    Yfrontal = (-90+90 / 0.5 * dYnose / dYtot) if dYtot != 0 else 0\n",
    "\n",
    "    return angle * 180 / np.pi, Xfrontal, Yfrontal\n",
    "\n",
    "    \n",
    "# load scrfd face detector model\n",
    "onnxmodel = 'models/scrfd_2.5g_kps.onnx'\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.5\n",
    "mynet = SCRFD(onnxmodel, confThreshold=confThreshold, nmsThreshold=nmsThreshold)\n",
    "\n",
    "deviceId = 0# select camera\n",
    "cap = cv2.VideoCapture(deviceId)\n",
    "\n",
    "tm = cv2.TickMeter()\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    \n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        print('No frames captured!')\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Inference\n",
    "    tm.start()# for calculating FPS\n",
    "    bboxes, lmarks, scores = mynet.detect(frame)# face detection\n",
    "    tm.stop()\n",
    "    \n",
    "    # process if at least one face detected\n",
    "    if bboxes.shape[0] > 0 or lmarks.shape[0] > 0:\n",
    "        \n",
    "        # Draw results on the input image\n",
    "        frame = visualize(frame, bboxes, lmarks, scores, fps=tm.getFPS())\n",
    "        \n",
    "        # Check if all coordinates of the highest score face in the frame\n",
    "        if are_coordinates_in_frame(frame, bboxes[0], lmarks[0]):\n",
    "            \n",
    "            roll, yaw, pitch = find_pose(lmarks[0])\n",
    "            \n",
    "            # visualize pose\n",
    "            lmarks = lmarks.astype(int)\n",
    "            start_point = (lmarks[0][2][0], lmarks[0][2][1])\n",
    "            end_point = (lmarks[0][2][0]-int(yaw), lmarks[0][2][1]-int(pitch))\n",
    "            \n",
    "            cv2.arrowedLine(frame, start_point, end_point, (255,0,0), 2)\n",
    "            bn = \"\\n\"\n",
    "            cv2.putText(frame, f\"roll: {int(roll)} -- yaw: {int(yaw)} -- pitch: {int(pitch)}\", \n",
    "                        (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=1)\n",
    "    \n",
    "    # Visualize results in a new Window\n",
    "    cv2.imshow('Face Pose', frame)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    tm.reset()\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "burma_card_reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
